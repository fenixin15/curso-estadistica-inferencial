\documentclass[12pt,t]{beamer}
% \documentclass[t]{beamer}
\usepackage[utf8]{inputenc}
\usepackage[catalan]{babel}
\usepackage{verbatim}
\usepackage{hyperref}
\usepackage{amsfonts,amssymb,amsmath,amsthm, wasysym}
\usepackage{listings}
\usepackage[T1]{fontenc}        
\usepackage{pgf}
%\usepackage{epsdice}
\usepackage{pgfpages}
\usepackage{tikz}
%\usetikzlibrary{arrows,shapes,plotmarks,backgrounds,trees,positioning}
%\usetikzlibrary{decorations.pathmorphing,calc,snakes}
%\usepackage{marvosym}
%
\usetheme[hideothersubsections,left]{Marburg}
\usecolortheme{sidebartab}
\useinnertheme[shadow]{rounded}
% \useoutertheme[footline=empty,subsection=true,compress]{infolines}
% \useoutertheme[footline=empty,subsection=true,compress]{miniframes}
% \usefonttheme{serif}

\setbeamertemplate{caption}[numbered]
\setbeamertemplate{navigation symbols}{}


\newcommand{\red}[1]{\textcolor{red}{#1}}
\newcommand{\green}[1]{\textcolor{green}{#1}}
\newcommand{\blue}[1]{\textcolor{blue}{#1}}
\newcommand{\gray}[1]{\textcolor{gray}{#1}}
\renewcommand{\emph}[1]{{\color{red}#1}}

\setbeamertemplate{frametitle}
{\begin{centering}
\medskip
\color{blue}
\textbf{\insertframetitle}
\medskip
\end{centering}
}
\usecolortheme{rose}
\usecolortheme{dolphin}
\mode<presentation>


\newcommand{\CC}{\mathbb{C}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\NN}{\mathbb{N}}
\newcommand{\KK}{\mathbb{K}}
\newcommand{\MM}{\mathcal{M}}
%\newcommand{\dbinom}{\displaystyle\binom}

\newcommand{\limn}{{\displaystyle \lim_{n\to\infty}}}
\renewcommand{\leq}{\leqslant}
\renewcommand{\geq}{\geqslant}
\def\tendeix{{\displaystyle\mathop{\longrightarrow}_{\scriptscriptstyle
n\to\infty}}}

\newcommand{\matriu}[1]{\left(\begin{matrix} #1 \end{matrix}\right)}

% \newcommand{\qed}{\hbox{}\nobreak\hfill\vrule width 1.4mm height 1.4mm depth 0mm
%     \par \goodbreak \smallskip}
%
% %
\theoremstyle{plain}
\newtheorem{teorema}{Teorema}
\newtheorem{prop}{Proposició}
\newtheorem{cor}{Coro\l.lari}
\theoremstyle{definition}
\newtheorem{Ejemplo}{Ejemplo}
\newtheorem{exerc}{Exercici}
\newtheorem{defin}{Definició}
\newtheorem{obs}{Observació}

\newcounter{seccions}
\newcommand{\seccio}[1]{\addtocounter{seccions}{1}
\medskip\par\noindent\textbf{\theseccions.
#1}\smallskip\par }

\newcommand{\EM}{\Omega}
\newcommand{\PP}{\mathcal{P}}

\title[\red{Matemáticas III GINF}]{}
\author[]{}
\date{}



\begin{document}
\beamertemplatedotitem

\lstset{backgroundcolor=\color{green!50}}
\lstset{breaklines=true}
\lstset{basicstyle=\ttfamily}


\section{Estimación puntual}

\begin{frame}
\vfill
\begin{center}
\gray{\LARGE Estimación puntual}
\end{center}
\vfill
\end{frame}






\subsection{Definiciones básicas}


\begin{frame}
\frametitle{Estadística inferencial}

El problema usual de la \emph{estadística inferencial} es:

\begin{itemize}

\item Queremos conocer el valor de una característica en una población
\medskip

\item No podemos medir esta característica en todos los individuos de la población
\medskip

\item Extraemos una muestra  aleatoria de la población,  medimos la característica en los  individuos de esta muestra e  \emph{inferimos} el valor de la característica para la toda la población

\begin{itemize}
\item ¿Cómo lo tenemos que hacer?
\item ¿Cómo tenemos que hacer la muestra?
\item ¿Qué nformacioón podemeos inferir?
\end{itemize}
\end{itemize}
\end{frame}



\begin{frame}
\frametitle{Ejemplos}

\begin{center}
\hspace*{-0.5cm}
\includegraphics[width=1.1\linewidth]{plagiUIB1.jpg}\bigskip

\hspace*{-0.5cm}\includegraphics[width=1.1\linewidth]{plagiUIB2.jpg}
\end{center}
\end{frame}


%
%\begin{frame}
%\frametitle{Ejemplos}
%\vspace*{-0.5cm}
%
%\begin{center}
%\includegraphics[width=\linewidth]{paro.jpg}
%\end{center}
%\end{frame}

\begin{frame}
\frametitle{Ejemplos}


\begin{center}
\includegraphics[width=\linewidth]{vacuna1.jpg}\medskip

\includegraphics[width=\linewidth]{vacuna2.jpg}
\end{center}


{\footnotesize \url{http://www.scielosp.org/pdf/rpsp/v8n6/3956.pdf}}
\end{frame}

\begin{frame}
\frametitle{Definiciones básicas}

\emph{Muestra aleatória simple (m.a.s.) de tamanyo $n$:} De una población de $N$ individuos, repetimos $n$ veces el proceso   consistente en escoger equiprobablemente un individuo de la población; \textit{los individuos escogidos se pueden repetir}
\bigskip

\blue{Ejemplo:} Escogemos  al azar $n$ estudiantes de la UIB (con reposición) para medirles la estatura
\bigskip

De esta manera, todas las muestras posibles de $n$ individuos (posiblemente repetidos: \emph{multiconjuntos}) tienen la misma probabilidad
\bigskip

%\href{http://www.latex-project.org/}{latex project}
\emph{\bf Leeros la \href{https://aprender-uib.github.io/AprendeR2/chap-muestreo.html}{lección 2 de AprendeR2} sobre muestreo}
\end{frame}


\begin{frame}
\frametitle{Definiciones básicas}

\emph{Estadístico} (\emph{Estimador puntual}): Una función que aplicada a una muestra nos permite \emph{estimar} un valor que queramos conocer sobre  tota la població
\bigskip

\blue{Ejemplo:} La media de les estaturas  de una muestra d e estudiantes de la UIB nos permite estimar la media de les alturas de todos los   estudiantes de la UIB
\bigskip

\end{frame}

\begin{frame}
\frametitle{Formalmente}

Una \emph{m.a.s.\ de tamaño $n$} (d'una v.a.\ $X$) es
\begin{itemize}
\item  un conjunt de $n$ còpies \blue{independents} de $X$, o

\item un conjunt de $n$ variables aleatòries  \blue{independents} $X_1,\ldots,X_n$, totes con la distribució de  $X$
\end{itemize}
\medskip


\blue{Ejemplo:} Sigui $X$ la v.a.\ ``triam un estudiant de la UIB y li mesuram l'alçada''. Una m.a.s.\ de $X$ de tamaño $n$ seran $n$ còpies independents $X_1,\ldots,X_n$ d'aquesta $X$.
\bigskip


Una \emph{realització} d'una m.a.s.\ són els $n$ valors $x_1,\ldots,x_n$ que prenen les v.a.\ $X_1,\ldots,X_n$

\end{frame}


\begin{frame}
\frametitle{Formalment}

Un  \emph{estadístic} $T$ es una funció aplicada a la muestra $X_1,\ldots,X_n$:
$$
T=f(X_1,\ldots,X_n)
$$
Aquest estadístic s'aplica a les realitzacions de la muestra
\medskip

\blue{Ejemplo:} La \emph{media muestral} de una m.a.s.\ $X_1,\ldots,X_n$ de tamaño $n$ es 
$$
\overline{X}:=\frac{X_1+\cdots+X_n}{n}
$$
Estima $E(X)$
\medskip

\blue{Ejemplo:} La media muestral de les alçades d'una  realització d'una m.a.s.\ d'alçades d'estudiants estima  l'alçada media d'un estudiant de la UIB




\end{frame}


\begin{frame}
\frametitle{Formalment}

Un  \emph{estadístic} $T$ es una funció aplicada a la muestra $X_1,\ldots,X_n$
$$
T=f(X_1,\ldots,X_n)
$$
\medskip

Per tant, un estadístic es una (nova) variable aleatòria, con distribució, esperança, etc.
\medskip

La \emph{distribució muestral} de $T$ es la distribució d'aquesta variable aleatòria
\medskip

Del coneixement d'aquesta distribució muestral, podrem estimar propietats de $X$ a partir de les  d'una muestra
\medskip

\emph{Error estàndard de $T$}: desviació típica de $T$


\end{frame}



\begin{frame}
\frametitle{Conveni}

\emph{\bf ELS ESTADÍSTICS, EN MAJÚSCULES; les realitzacions, en minúscules}
\medskip

\blue{Ejemplo:} 
\begin{itemize}
\item $X_1,\ldots,X_n$ una m.a.s.\ y 
$$
\overline{X}:=\frac{X_1+\cdots+X_n}{n}
$$
la media muestral\medskip


\item $x_1,\ldots,x_n$ una realització d'aquesta m.a.s.\ y 
$$
\overline{x}:=\frac{x_1+\cdots+x_n}{n}
$$
la media (muestral) d'aquesta realització
\end{itemize}

\end{frame}




\begin{frame}
\frametitle{La vida real}

A la vida real, les muestras aleatòries se solen prendre sense reposició (sense repeticions).
No són muestras aleatòries simples. pero:
\begin{itemize}
\item Si $N$ es molt mes gran que $n$,  els resultatspara  m.a.s.\ valen (aproximadament) en aquest cas, perquè les repeticions són improbables y les variables aleatòries que formen la muestra són gairebé independents
\smallskip

 Farem l'abús de llenguatge de dir que en aquest cas tconé tenim una m.a.s.
\medskip

\item Si $n$ es relativament gran, sovint es poden donar versions corregides dels estadístics
\end{itemize}

\end{frame}


\begin{frame}
\frametitle{La vida real}

\blue{Ejemplo:} La UIB té uns 12000 estudiants

\begin{center}
\includegraphics[width=0.8\linewidth]{UIB.pdf}
\end{center}

\end{frame}


%%Concurs1
%La UIB té uns 16000 estudiants. 
%
%a) Quina es la probabilitat que si en triam n a l'atzar, un rere l'altre y con reposició, siguin tots diferents?
%b) Definiu una funció de R que, aplicada a n, doni aquesta probabilitat
%c) Calculau la llista $(f(n))_{n=2,150}$ (per aplicar una funció a una llista, si directament no funciona, podeu emprar sapply(llista, funció)). Quin es el nombre màxim d'estudiants que podem triar de manera que la probabilitat que siguin tots diferents sigui com a mínim del 95\%?
%d) La funció $f$, es aproximadament lineal, polinòmica o exponencial (o cap de les tres coses) en $n$? En cas afirmatiu, trobau la funció que l'aproxima, y confirmau con un gràfic aquesta aproximació.



\subsection{media muestral}
\begin{frame}
\frametitle{media muestral}

Sigui $X_1,\ldots, X_n$ una m.a.s.\ de tamaño $n$ d'una v.a.\ $X$ d'esperança $\mu_X$ y desviació típica $\sigma_X$
\medskip

La \emph{media muestral} es
$$
\overline{X}=\frac{X_1+\cdots+X_n}{n}
$$

\begin{teorema}
En aquestes condicions
$$
E(\overline{X})=\mu_X,\quad \sigma_{\overline{X}}=\frac{\sigma_X}{\sqrt{n}}
$$
\end{teorema}

 $\sigma_{\overline{X}}$ es l'\emph{error estàndard} de $\overline{X}$



\end{frame}

\begin{frame}
\frametitle{media muestral}

$$
\overline{X}=\frac{X_1+\cdots+X_n}{n}
$$
\begin{itemize}
\item es un estimador puntual de $\mu_X$
\medskip

\item \emph{$E(\overline{X})=\mu_X$}
\begin{itemize}
\item El valor esperat de $\overline{X}$ es $\mu_X$
\medskip

\item Si prenem moltes vegades una m.a.s.\ y en calculam la media muestral, el valor mitjà d'aquestes mitjanes tendeix molt probablement a ser $\mu_X$
\end{itemize}
\bigskip

\item \emph{$\sigma_{\overline{X}}= \sigma_X/\sqrt{n}$}: la variabilitat dels resultats de $\overline{X}$ tendeix a 0 quan prenem muestras grans
\end{itemize}

\end{frame}

\begin{frame}[fragile]
\frametitle{media muestral}
\vspace*{-2ex}

{\small
\begin{verbatim}
> # tests.txt=notes dels tests de BL y BQ
> tests=scan("tests.txt")
Read 185 items
> mean(tests)
[1] 55.43243
> set.seed(100)
> mitjanes=replicate(10^4,
    mean(sample(tests,40,rep=TRUE)))
> mean(mitjanes)
[1] 55.45814
> #sd, per fer via
> c(sd(tests)/sqrt(40),sd(mitjanes))
[1] 3.390031 3.420459
\end{verbatim}
}

\end{frame}







\begin{frame}
\frametitle{Ejemplo}

S'ha pres una m.a.s.\ de 10 estudiants de la UIB, y les seves alçades han estat
$$
1.62,1.75,1.64,1.69,1.83,1.85,1.72,1.61,1.93, 1.62
$$
Podem estimar l'alçada media dels estudiants de la UIB:

$$
\overline{x}=\frac{1.62+1.75+1.64+\cdots+1.62}{10}=1.726
$$

Com de ``fina'' es aquesta estimació? No us perdeu el proper tema!

\end{frame}


\begin{frame}
\frametitle{Combinació lineal de normals es normal}
\begin{teorema}
Si $Y_1,\ldots,Y_n$ son v.a.\ normals independents, cada $Y_i\sim N(\mu_i,\sigma_i)$, y $a_1,\ldots,a_n,b\in \RR$ aleshores
$$
Y=a_1Y_1+\cdots+a_nY_n+b
$$
es una v.a.\ $N(\mu,\sigma)$ con $\mu$ y $\sigma$ les que toquen:
\begin{itemize}
\item $E(Y)=a_1\mu_1+\cdots+a_n\mu_n+b$
\medskip

\item $\sigma(Y)^2=a_1^2\sigma_1^2+\cdots+a_n^2\sigma_n^2$
\end{itemize}
\end{teorema}


\end{frame}




\begin{frame}
\frametitle{Cas $X$ normal}
\begin{teorema}
Sigui $X_1,\ldots, X_n$ una m.a.s.\ d'una v.a.\ $X$ d'esperança $\mu_X$ y desviació típica $\sigma_X$.
Si $X$ es $N(\mu_X,\sigma_X)$, aleshores
$$
\overline{X}\mbox{ es }N\Big(\mu_X,\frac{\sigma_X}{\sqrt{n}}\Big)
$$
i per tant
$$
Z=\frac{\overline{X}-\mu_X}{\frac{\sigma_X}{\sqrt{n}}}\mbox{ es }N(0,1)
$$
\end{teorema}

$Z$ es l'\emph{expressió tipificada} de la media muestral



\end{frame}




\begin{frame}
\frametitle{Teorema Central del Límit}
\begin{teorema}
Sigui $X_1,\ldots, X_n$ una m.a.s.\ d'una v.a.\ $X$ \emph{qualsevol} d'esperança $\mu_X$ y desviació típica $\sigma_X$. Quan $n\to \infty$, 
$$
\overline{X}\to N\Big(\mu_X,\frac{\sigma_X}{\sqrt{n}}\Big)
$$
i per tant
$$
Z=\frac{\overline{X}-\mu_X}{\frac{\sigma_X}{\sqrt{n}}}\to N(0,1)
$$
(Aquestes convergències refereixen a les distribucions.)
\end{teorema}




\end{frame}

\begin{frame}
\frametitle{Teorema Central del Límit}

\begin{block}{``Teorema''}
Si $n$ es gran (\emph{$n\geq 30$ o \underline{\textbf{40}}}), $\overline{X}$ es aproximadament normal, con esperança $\mu_X$ y desviació típica $\dfrac{\sigma_X}{\sqrt{n}}$
\end{block}
\bigskip

\blue{Ejemplo:} Tenim una v.a.\ $X$ de media $\mu_X=3$ y desv. típ. $\sigma_X=0.2$. Prenem muestras aleatòries simples de tamaño 50. La distribució de la media muestral $\overline{X}$ es aproximadament
$$
N\Big(3,\frac{0.2}{\sqrt{50}}\Big)=N(3,0.0283)
$$
\end{frame}

\begin{frame}[fragile]
\frametitle{Teorema Central del Límit}
\small

\begin{verbatim}
> hist(mitjanes,freq=FALSE, main="Histograma 
 de les mitjanes de 10000 muestras de 40 notes")
> lines(density(mitjanes),lty=2,lwd=2,col="red")
> curve(dnorm(x,mean(tests),sd(tests)/sqrt(40)),
 lty=3,lwd=2,col="blue",add=TRUE)
> legend("topright",legend=c("densitat","normal"),
 lwd=c(2,2),lty=c(2,3),col=c("red","blue"))
\end{verbatim}

\end{frame}

\begin{frame}
\frametitle{Teorema Central del Límit}
\vspace*{-4ex}

\begin{center}
\includegraphics[width=0.8\linewidth]{hist-test}
\end{center}



\end{frame}




\begin{frame}
\frametitle{Ejemplo}
\vspace*{-2ex}

L'alçada d'una espècie de matolls té valor mitjà  $115$ cm, con una desviació típica de $25$. Prenem una m.a.s.\ de $100$ matolls d'aquesta espècie.
\medskip

\blue{Quina es la probabilitat que la media muestral de les alçades sigui $\leq 110$ cm?}
\medskip

$\displaystyle Z=\frac{\overline{X}-\mu_{X}}{\frac{\sigma_{X}}{\sqrt{n}}}=
\frac{\overline{X}-115}{2.5}$ es (\red{aproximadament}) $N(0,1)$
\medskip

$\begin{array}{rl}
P(\overline{X}\leq 110)  &\displaystyle= P\Big(Z\leq \frac{110-115}{2.5}\Big)= P(Z\leq -2)\\[2ex]
& \displaystyle=0.0228
\end{array}$


\end{frame}



\begin{frame}
\vspace*{-2ex}

\frametitle{Ejemplo}
L'alçada d'una espècie de matolls té valor mitjà  $115$ cm, con una desviació típica de $25$. Prenem una m.a.s.\ de $100$ matolls d'aquesta espècie.
\medskip

\blue{Quina es la probabilitat que la media muestral de les alçades estigui entre $113$ cm y $117$ cm?}
\medskip


\end{frame}








\begin{frame}
\frametitle{media muestral sense reposició}

Sigui $X_1,\ldots, X_n$ una m.a.\ \emph{sense reposició} de tamaño $n$ d'una v.a.\ $X$ d'esperança $\mu_X$ y desviació típica $\sigma_X$. 
\medskip

Si $n$ es  petit en relació a la tamaño $N$ de la població, tot funciona (per aproximació) com fins ara
\medskip

Si $n$ es gran en relació a $N$, aleshores
$$
E(\overline{X})=\mu_X,\quad \sigma_{\overline{X}}=\frac{\sigma_X}{\sqrt{n}}\cdot\red{\sqrt{\frac{N-n}{N-1}}}
$$
(\emph{factor de població finita})
\medskip

El T.C.L. ja no val tal qual en aquest darrer cas



\end{frame}

\subsection{Proporció muestral}
\begin{frame}
\frametitle{Proporció muestral}

Sigui $X$ una v.a.\ Bernoulli de paràmetre $p_X$ (1 èxit, 0 fracàs). Sigui $X_1,\ldots,X_n$ una m.a.s.\ de tamaño $n$ de $X$. 
\medskip

$S=\sum_{i=1}^n X_i$ es el nombre d'èxits observats. es $B(n,p)$.
\medskip

La \emph{proporció muestral} es 
$$
\widehat{p}_X=\frac{S}{n}
$$
i es un estimador de $p_X$
\medskip

Fixau-vos que $\widehat{p}_X$ es un cas particular de $\overline{X}$, per tant val tot el que hem dit fins arapara  mitjanes muestrals


\end{frame}


\begin{frame}
\frametitle{Proporció muestral}
$\widehat{p}_X=\dfrac{S}{n}$
\medskip

\begin{itemize}
\item $E(\widehat{p}_X)=p_X$
\medskip


\item $\displaystyle \sigma_{\widehat{p}_X}=\sqrt{\frac{p_X(1-p_X)}{n}}$, l'\emph{error estàndard} de la proporció muestral
\medskip

\item Si la muestra es sense reposició y $n$ es relativament gran,
$\displaystyle\sigma_{\widehat{p}_X}=\sqrt{\frac{p_X(1-p_X)}{n}}\cdot\red{\sqrt{\frac{N-n}{N-1}}}$
\end{itemize}

\end{frame}


\begin{frame}
\frametitle{Proporció muestral}
\vspace*{-2ex}

Pel T.C.L.:

\begin{block}{``Teorema''}
Si $n$ es gran (\emph{$n\geq 30$ o \underline{\textbf{40}}}) y la muestra es aleatòria simple, 
$$
\frac{\widehat{p}_X-p_X}{\sqrt{\frac{{p}_X(1-{p}_X)}{n}}}\approx N(0,1)
$$
\end{block}

\end{frame}


\begin{frame}
\frametitle{Ejemplo}
\vspace*{-2ex}

En una muestra aleatòria de 60 estudiants de la UIB del curs 2013-14, 37 varen ser dones. Estimau la fracció de dones entre els estudiants de la UIB
\medskip

$$
\frac{37}{60}=0.6167
$$
\vspace*{-2ex}

\begin{center}
\includegraphics[width=0.7\linewidth]{sexeUIB}
\end{center}


\end{frame}


\begin{frame}
\frametitle{Ejemplo}
\vspace*{-2ex}

\blue{Un  59\% dels estudiants de la UIB són dones. Si prenem una m.a.s.\ de 60 estudiants, quina es la probabilitat que la proporció muestral de dones sigui superior al 61\%?}
\medskip 


   
\end{frame}


\subsection{Variància muestral}

\begin{frame}
\frametitle{Variància muestral}

Sigui $X_1,\ldots, X_n$ una m.a.s.\ de tamaño $n$ d'una v.a.\ $X$ d'esperança $\mu_X$ y desviació típica $\sigma_X$
\medskip

La \emph{variància muestral} es
$$
\widetilde{S}_{X}^2=\frac{\sum_{i=1}^n (X_{i}-\overline{X})^2}{n-1}
$$
La \emph{desviació típica muestral} es 
$$
\widetilde{S}_{X}=+\sqrt{\widetilde{S}_{X}^2}
$$
A mes, escriurem
$$
S^2_{X}=\frac{\sum_{i=1}^n (X_{i}-\overline{X})^2}{n}=\frac{(n-1)}{n}\widetilde{S}^2_{X}\quad\mbox{ y }\quad S_X=+\sqrt{S_X^2}
$$
\end{frame}


\begin{frame}
\frametitle{Variància muestral: Propietats}
\begin{itemize}
\item $\displaystyle S^2_X=\frac{\sum_{i=1}^n (X_{i}-\overline{X})^2}{n}=\left(\frac{\sum_{i=1}^n
X_{i}^2}{n}-\overline{X}^2\right)$\medskip

\item $\displaystyle \widetilde{S}_{X}^2=\frac{n}{n-1}\left(\frac{\sum_{i=1}^n
X_{i}^2}{n}-\overline{X}^2\right)$\medskip

\end{itemize}


\begin{teorema}
Si la v.a.\ $X$ es normal, aleshores $E(\widetilde{S}_{X}^2)=\sigma_{X}^2$ y 
la v.a.
$$
\frac{(n-1)\widetilde{S}_{X}^2}{\sigma_{X}^2}
$$
té distribució $\chi_{n-1}^2$
\end{teorema}
\end{frame}


\begin{frame}
\frametitle{La distribució $\chi_n^2$}

La distribució $\chi_n^2$ ($\chi$: en català, \emph{khi}; en castellà, \emph{ji}; en anglès, \emph{chi}), on $n$ són els \emph{graus de llibertat}:
\begin{itemize}
\item es la de 
$$
X=Z_{1}^{2}+Z_{2}^{2}+\cdots +Z_{n}^{2}
$$ 
on  $Z_{1},Z_{2},\ldots, Z_{n}$ son v.a.\  independents  $N(0,1)$
\medskip

\item Té densitat
$$
f_{\chi_n^2}(x)={\frac{1}{2^{n/2} \Gamma (n/2)}} x^{(n/2)-1} e^{-x/2}\quad\mbox{ si $x\geq 0$}
$$
on $\Gamma(x)=\int_{0}^{\infty} t^{x-1}e^{-t}\, dt$ si $x> 0$

\end{itemize}
\end{frame}


\begin{frame}
\frametitle{La distribució $\chi_n^2$}

\begin{itemize}
\item La distribució està tabulada (\emph{Teniu les taules a Campus Extens}), y con R es \texttt{chisq}
\bigskip

\item Si $X_{\chi_n^2}$ es una v.a.\ con distribució  $\chi_n^2$,
$$E(X_{\chi_n^2})=n,\quad Var(X_{\chi_n^2})=2 n$$
\medskip

\item ${\chi_n^2}$ s'aproxima a una distribució normal $N(n,\sqrt{2n})$para  $n$ gran
($n>40$ o $50$) 
\end{itemize}

\end{frame}

\begin{frame}
\frametitle{La distribució $\chi_n^2$}
\vspace*{-1cm}

\begin{center}
\includegraphics[width=\linewidth]{taulachi.jpg}
\end{center}

$F_{\chi_{10}^2}(25.188)=0.995$,\  $F_{\chi_{20}^2}(26.5)\approx 0.85$\quad  \blue{Feu el test!}

\end{frame}


\begin{frame}
\frametitle{La distribució $\chi_n^2$}
\vspace*{-1cm}

\begin{center}
\includegraphics[width=\linewidth]{./dibujos-001}

Funció  de densitat de $\chi^2_n$para  alguns $n$
\end{center}
\end{frame}

\begin{frame}
\frametitle{Ejemplo}
\vspace*{-2ex}

L'augment diari del pes d'un pollastre d'una granja segueix una
distribució normal con desviació típica $1.7$. Es pren una
muestra de 12 pollastres. Suposam que aquesta muestra es petita respecte del total de la població de la granja.
\medskip

\blue{Probabilitat que la desviació típica muestral
sigui $\leq 2.5$?}
\medskip

Sigui $X$= l'augment diari del pes d'un pollastre. Sabem que $\sigma_{X}^2=(1.7)^2=2.89$. Com que $X$ es normal
 y $n=12$, tenim que
$$
\frac{11\cdot \widetilde{S}_{X}^2}{2.89}=\frac{(n-1)\widetilde{S}_{X}^2}{\sigma_{X}^2}\sim \chi^2_{11}
$$

        
\end{frame}


\begin{frame}
\frametitle{Ejemplo}
\vspace*{-2ex}

L'augment diari del pes d'un pollastre d'una granja segueix una
distribució normal con desviació típica $1.7$. Es pren una
muestra de 12 pollastres. Suposam que aquesta muestra es petita respecte del total de la població de la granja.
\medskip

\blue{Probabilitat que la desviació típica muestral
sigui $\leq 2.5$?}
\medskip

$\dfrac{11\widetilde{S}_{X}^2}{2.89}\sim \chi^2_{11}$
\medskip

$\begin{array}{l}
\displaystyle P(\widetilde{S}_{X}<2.5)= P\left(\widetilde{S}_{X}^2<2.5^2\right)\\
\quad \displaystyle =P\left(\frac{11\cdot \widetilde{S}_{X}^2}{2.89}<\frac{11
\cdot 2.5^2}{2.89}\right)= P(\chi_{11}^2<23.79)\\
\only<2>{\quad\displaystyle=\mbox{\texttt{pchisq(23.7889,11)}}=0.986}
\only<3>{\quad \displaystyle \approx P(\chi_{11}^2<24.725)=0.99}
\end{array}$
        
\end{frame}


\subsection{Propietats dels estimadors}


\begin{frame}
\frametitle{Estimadors no segados}

Quan un estimador es bo?
\medskip

Un estimador puntual $\widehat{\theta}$ d'un paràmetre poblacional
$\theta$ es  \emph{no segado} quan el seu valor esperat es precisament el valor del paràmetre:
$$
E(\widehat{\theta})=\theta
$$ 
Es diu aleshores que l'estimació puntual es \emph{no essesgoada}.
\medskip

El  \emph{sesgo} de $\widehat{\theta}$ es $E(\widehat{\theta})-\theta$

\end{frame}


\begin{frame}
\frametitle{Estimadors no segados}


\blue{Ejemplos}

\begin{itemize}
\item $E(\overline{X})=\mu_X$: $\overline{X}$ es estimador no segado de $\mu_X$
\medskip

\item $E(\widehat{p}_X)=p_X$: $\widehat{p}_X$ es estimador no segado de $p_X$
\medskip

\item $E(\widetilde{S}_{X}^2)=\sigma_X^2$ si $X$ es normal: $\widetilde{S}_{X}^2$ es estimador no segado de $\sigma_X^2$ quan $X$ es normal
\medskip

\item $E({S}_{X}^2)=\dfrac{n-1}{n}\sigma_X^2$ si $X$ es normal; per tant
\emph{${S}_{X}^2$ es segado}, con sesgo
$$
E({S}_{X}^2)-\sigma_X^2=\dfrac{n-1}{n}\sigma_X^2-\sigma_X^2=-\dfrac{\sigma_X^2}{n}\ \tendeix\ 0
$$

\end{itemize}

\end{frame}


\begin{frame}
\frametitle{Estimadors eficients}

Quan un estimador es \emph{millor}?
\medskip

Quan es no segado y té poca variabilitat (així es mes probable que aplicat a una m.a.s.\ doni prop del valor esperat)
\medskip

\emph{Error estàndard d'un estimador $\widehat{\theta}$}: la seva desviació típica
$$\sigma_{\widehat{\theta}}=\sqrt{Var(\widehat{\theta})}$$
\medskip

\end{frame}


\begin{frame}
\frametitle{Estimadors eficients}

Donats dos estimadors $\widehat{\theta}_1$, $\widehat{\theta}_2$ no segados (o con sesgo $\tendeix 0$) del mateix paràmetre $\theta$, direm que 
\begin{center}
$\widehat{\theta}_1$ es \emph{mes eficient} que $\widehat{\theta}_2$
\end{center}
 quan $$\sigma_{\widehat{\theta}_1}< \sigma_{\widehat{\theta}_2},$$  es a dir, quan $$Var(\widehat{\theta}_1)< Var(\widehat{\theta}_2)$$


\end{frame}


\begin{frame}
\frametitle{Estimadors eficients}

\blue{Ejemplo}: Sigui $X$ una v.a.\ con media $\mu_X$ y desviació típica $\sigma_X$
\medskip

Considerem la mediana $Me=Q_{0.5}$ de la realització d'una m.a.s.\ de $X$ com a estimador puntual de $\mu_X$
\medskip

Si $X$ es normal, 
$$
\begin{array}{l}
E(Me)=\mu_X,\\
\displaystyle  Var(Me)\approx \frac{\pi}{2}
     \frac{\sigma_{X}^2}{n}\approx \frac{1.57 \sigma_{X}^2}{n}=1.57Var(\overline{X})
\end{array}
$$
Per tant, $Me$ es un estimador no segado de   $\mu_X$, pero menos eficient que $\overline{X}$



\end{frame}


\begin{frame}
\frametitle{Estimadors  eficients}

\begin{itemize}
\item Si la població es normal, la media muestral es l'estimador
no segado mes eficient de la media poblacional
\medskip

\item Si la població es Bernoulli, la proporció muestral es l'estimador
no segado mes eficient de la proporció poblacional
\medskip

\item Si la població es normal, la variància muestral es l'estimador
no segado  mes eficient de la variància poblacional
 \end{itemize}




\end{frame}


\begin{frame}
\frametitle{Estimadors  eficients}

Hem dit que si la població es normal, la variància muestral es l'estimador
no segado  mes eficient de la variància poblacional
\medskip

L'estimador ``variància''
$$
S_X^2=\frac{(n-1)}{n} \widetilde{S}_X^2
$$   
encara es mes eficient, pero  té sesgo $\tendeix 0$
\medskip

Si $n$ es petit ($\leq 30$ o 40), es millor fer servir la variància muestral $\widetilde{S}_X^2$ per estimar la variància, ja que el sesgo influeix, pero si $n$ es gran, el sesgo ja no es tan important y es pot fer servir $S_X^2$


\end{frame}



\begin{frame}
\frametitle{Ejemplo: Estimació de poblacions}

Tenim una població numerada $1,2,\ldots,N$\medskip

En prenem una m.a.s. $x_1,\ldots,x_n$; sigui
$m=\max(x_1,\ldots,x_n)$
\medskip

\begin{block}{Teorema}
L'estimador no segado mes eficient de $N$ es
$$
\widehat{N}=m+\frac{m-n}{n}
$$
\end{block}
\bigskip


Un problema de rellevància històrica:

{\scriptsize \url{http://en.wikipedia.org/wiki/German_tank_problem}}

\end{frame}



\begin{frame}[fragile]
\frametitle{Ejemplo: Estimació de poblacions}
\vspace*{-2ex}

\blue{Ejemplo:}
Assegut en un bar del Passeig Marítim he apuntat les llicències dels 40 primers taxis que he vist:
\vspace*{-1ex}

{\footnotesize
\begin{verbatim}
> taxis=c(1217,600,883,1026,150,715,297,137,508,134,
  38,961,538,1154,314,1121,823,158,940,99,977,286,
  1006,1207,264,1183,1120,498,606,566,1239,860,114,
  701,381,836,561,494,858,187)
\end{verbatim}
}
\vspace*{-1ex}

Suposaré que formen una m.a.s. dels taxis de Palma. Aleshores, estim que el nombre de taxis de Palma 
es
\vspace*{-1ex}

{\footnotesize
\begin{verbatim}
> N=max(taxis)+(max(taxis)-length(taxis))/length(taxis)
> N
[1] 1268.975
\end{verbatim}
}
\vspace*{-1ex}

En realitat, n'hi ha 1246 
\medskip

{\scriptsize \url{http://www.caib.es/eboibfront/es/2014/10195/551436/departamento-de-movilidad-seccion-de-transportes-r}

}


\end{frame}

\begin{frame}
\frametitle{Estimadors màxim versemblants}

\blue{Com trobam bons estimadors?}
\medskip

Sigui $X$ una v.a.\ \emph{discreta} con densitat 
$$
f_X(x;\lconda)
$$
que depèn d'un
paràmetre desconegut $\lconda$
\medskip

Sigui $X_{1},\ldots X_{n}$ una m.a.s.\ de $X$, y sigui $x_1,x_2,\ldots,x_n$ una realització d'aquesta muestra
\medskip


La \emph{funció de versemblança} de la muestra es la probabilitat condicionada següent:
$$
\begin{array}{rl}
\red{L(\lconda|x_1,x_2,\ldots,x_n)} & := P(x_1,x_2,\ldots,x_n|\lconda)\\&=P(X_1=x_1)\cdots P(X_n=x_n)\\
& = f_X(x_1;\lconda)\cdots f_X(x_n;\lconda)
\end{array}
$$

\end{frame}

\begin{frame}
\frametitle{Estimadors màxim versemblants}

Donada la funció de versemblança $L(\lconda|x_1,\ldots,x_n)$ de la muestra, indicarem per 
$$
\red{\hat{\lconda}(x_1,\ldots,x_n)}
$$ 
el valor del paràmetre $\lconda$ on s'aconsegueix el màxim
de $L(\lconda|x_1,\ldots,x_n)$. Serà una funció de $x_1,\ldots,x_n$.
\medskip


\begin{defin}
\begin{small}
Un estimador $\hat{\lconda}$ d'un paràmetre $\lconda$ es \emph{màxim versemblant} (\emph{MV}, en anglès \emph{EM}) quan,para  cada m.a.s, la probabilitat d'observar-la es màxima quan el paràmetre pren el valor de l'estimador aplicat a la muestra, es a dir, quan la funció de versemblança
$$L(\lconda|x_1,x_2,\ldots,x_n)= P(x_1,x_2,\ldots,x_n|\lconda)$$
 assoleix el seu màxim.
 \end{small}
\end{defin}
\end{frame}

\begin{frame}
\frametitle{Estimadors màxim versemblants}

\blue{Ejemplo}: Supongamos que tenim una v.a. Bernoulli $X$ de probabilitat d'èxit $p$ desconeguda\medskip

Per a cada m.a.s. $x_1,\ldots,x_n$ de $X$, siguin \red{$\widehat{p}_x$} la seva proporció muestral y  \red{$P(x_1,\ldots,x_n\mid p)$} la probabilitat d'obtenir-la quan el paràmetre pren el valor $p$

\begin{block}{Teorema}
El valor de $p$para l qual $P(x_1,\ldots,x_n\mid p)$ es màxim es $\widehat{p}_x$.
\end{block}

La proporció muestral es un estimador MV de $p$. Vegem-ho. 

\end{frame}


\begin{frame}
\frametitle{Estimadors màxim versemblants}

\vspace{1cm}

\begin{obs}
En general, com que $\ln$ es creixent, en lloc de maximitzar $L(\lconda|x_1,\ldots,x_n)$, maximitzam
$$
\ln(L(\lconda|x_1,\ldots,x_n))
$$
que sol ser mes fàcil (productes $\to$ sumes).
\end{obs}
\end{frame}


\begin{frame}
\frametitle{Estimadors màxim versemblants}
Sigui $X_{1},\ldots X_{n}$ una m.a.s.\ d'una v.a.\ Bernoulli $X$ de paràmetre $p$ (desconegut). Posem $q=1-p$
$$
\begin{array}{c}
f_X(1;p)=P(X=1)=p,\quad 
f_X(0;p)=P(X=0)=q
\end{array}
$$
es a dir, per $x\in\{0,1\}$, resulta que 
$$f_X(x;p)=P(X=x)=p^{x} q^{1-x}.$$

La funció de versemblança es:
$$
\begin{array}{l}
L(p|x_1,\ldots,x_n) = f_{X}(x_1;p)\cdots f_{X}(x_n;p)\\[1ex]
\quad =
p^{x_{1}}q^{1-x_{1}} \cdots  p^{x_{n}}q^{1-x_{n}}
\\[1ex]
\quad = p^{\sum_{i=1}^n x_{i}} q^{\sum_{i=1}^n (1-x_{i})}= p^{\sum_{i=1}^n x_{i}} q^{n-\sum_{i=1}^n x_{i}}\\[1ex]
\quad =p^{\sum_{i=1}^n x_{i}} (1-p)^{n-\sum_{i=1}^n x_{i}}
\end{array}
$$
\end{frame}

\begin{frame}
\frametitle{Ejemplo}
La funció de versemblança es
$$
\begin{array}{rl}
L(p|x_1,\ldots,x_n) & =p^{\sum_{i=1}^n x_{i}} (1-p)^{n-\sum_{i=1}^n x_{i}}\\
& =p^{n\overline{x}}(1-p)^{n-n\overline{x}}
\end{array}
$$
on $\overline{x}=\dfrac{\sum_{i=1}^n x_{i}}{n}$
\medskip


Volem trobar el valor de $p$ on s'assoleix el màxim d'aquesta funció (on $\overline{x}$ es un paràmetre: la variable es $p$)
\medskip

Maximitzarem el seu logaritme:
$$
\begin{array}{l}
\ln(L(p|x_1,\ldots,x_n))\\
\qquad \displaystyle=n\overline{x}\ln(p)+n(1-\overline{x})\ln(1-p)
\end{array}
$$
\end{frame}

\begin{frame}
\frametitle{Ejemplo}
Derivem respecte de $p$:
$$
\begin{array}{l}
\ln(L(p|x_1,\ldots,x_n))'\\
\qquad \displaystyle=n\overline{x}\frac{1}{p}-n(1-\overline{x})\frac{1}{1-p}\\
\qquad \displaystyle=\frac{1}{p(1-p)}\Big((1-p)n\overline{x}-pn(1-\overline{x})\Big)\\
\qquad \displaystyle=\frac{1}{p(1-p)}(n\overline{x} -pn)=\frac{n}{p(1-p)}(\overline{x} -p)\\
\end{array}
$$
Estudiem el signe:
$$
\begin{array}{rl}
\ln(L(p|x_1,\ldots,x_n))'\geq 0 &\displaystyle \Leftrightarrow \overline{x} -p\geq 0\\ &\displaystyle \Leftrightarrow
p\leq\overline{x}
\end{array}
$$
\end{frame}

\begin{frame}
\frametitle{Ejemplo}
Per tant
$$
\ln(L(p|x_1,\ldots,x_n))\left\{
\begin{array}{l}
\mbox{ creixent fins $\overline{x}$}\\
\mbox{ decreixent a partir de $\overline{x}$}\\
\mbox{ \red{té un màxim a $\overline{x}$}}
\end{array}\right.
$$

\vspace{1cm}

I el resultat queda demuestrat. $L(\widehat{p}_X|x_1,\ldots,x_n)\geq L(p|x_1,\ldots,x_n)$para  qualsevol  $p$
\end{frame}

\begin{frame}
\frametitle{Alguns estimadors MV}
\vspace*{-1ex}

\begin{itemize}
\item $\widehat{p}_x$ es l'estimador MV del paràmetre $p$ d'una v.a. Bernoulli
\medskip

\item $\overline{X}$  es l'estimador MV del paràmetre $\lconda$ d'una v.a. Poisson
\medskip

\item $\overline{X}$  es l'estimador MV del paràmetre $\mu$ d'una v.a. normal
\medskip

\item $S_X^2$ (\red{\underline{no} $\widetilde{S}_X^2$}) es l'estimador MV del paràmetre $\sigma^2$ d'una v.a. normal
\medskip

\item El màxim (\red{\underline{no}  $\widehat{N}$}) es l'estimador MV de la $N$ al problema dels taxis

\end{itemize}

\end{frame}


\begin{frame}
\frametitle{Ejemplo: $\lconda$para  una Poisson}

\vspace{1cm}

\begin{exerc}
Sigui $X$ una característica d'una població que segueix una llei $Po(\lconda)$, con $\lconda>0$ desconegut. Prenem una muestra aleatòria simple $X_1,\ldots,X_n$ d'aquesta població y obtenim els resultats $x_1,\ldots,x_n$. 

\medskip

Trobau l'estimador màxim versemblant de $\lconda$para  $x_1,\ldots,x_n$.
\end{exerc}

\end{frame}



\begin{frame}
\frametitle{Ejemplo: Marca-recaptura}

En una población hay $N$ individuos, capturamos $K$, los marcamos y los  volvemos a soltar.  Ahora volvemos a capturar $n$, de los que   $k$ están marcados. A partir de estos datos, queremos estimar $N$.
\bigskip

Suposam que $N$ y $K$ no han canviado de la primera a la segunda captura
\bigskip

$X=$``Un individuo esté marcado'' es $Be(p)$ con $p=\dfrac{K}{N}$
\bigskip

$X_1,\ldots,X_n$ la muestra capturada la segunda vez: $\widehat{p}_X=\frac{k}{n}$

\end{frame}


\begin{frame}
\frametitle{Ejemplo: Marca-recaptura}

$\widehat{p}_X$ es un estimador máximo verosimil $p$: estimamos que
$$
\dfrac{K}{N}=\dfrac{k}{n}\Rightarrow N=\frac{n\cdot K}{k}
$$

Por lo tant, el estimador
$$
\red{\widehat{N}=\frac{n\cdot K}{k}}
$$
 maximiza  la probabilidad  de la observación ``$k$ marcados de $n$ capturados''. es el \emph{estimador màxim versosimil} de $N$.

\end{frame}

\begin{frame}
\frametitle{Ejemplo: Marca-recaptura}

Supongamos que hemos marcado 15 peixos de lago, y que en una captura de 10 peces, hay  4 marcados. ¿Quantos peces estimais  que conté el llac?
\medskip

$$
\widehat{N}=\frac{15\cdot 10}{4}=37.5
$$
Por tanto, estimamos que habrá entre 37 y 38 peces en el  lago

\end{frame}


\begin{frame}[fragile]
\frametitle{Ejemplo: Marca-recaptura}
\vspace*{-0.8cm}

$$
P(\mbox{$k$ marcados de $n$ capturados})=\dfrac{\binom{K}{k}\cdot \binom{N-K}{n-k}}{\binom{N}{n}}
$$

<<>>=
N=15:100
p=choose(15,4)*choose(N-15,6)/choose(N,10)
plot(N,p,type="h",xaxp=c(15,100,17))
@
%\vspace*{-4ex}

\begin{center}
\includegraphics[width=0.65\linewidth]{marca.pdf}
\end{center}


\end{frame}


\begin{frame}
\frametitle{Ejemplo: Marca-recaptura}

El estimador
$$
\widehat{N}=\frac{n\cdot K}{k}
$$
es segado, con sesgo $\tendeix 0$
\bigskip

El \emph{estimador de Chapman}
$$
\widehat{N}=\frac{(n+1)\cdot (K+1)}{k+1}-1
$$
es menos segado para  muestras petites, y no segado si $K+n\geq N$ (pero no máximo verosímil)
\end{frame}


\end{document}



