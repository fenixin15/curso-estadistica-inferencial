---
title: 'Estimación puntual'
author: "Ricardo Alberich Martí, Juan Gabriel Gomila Salas, Arnau Mir Torres."
date: ""
output:
  beamer_presentation: default
  powerpoint_presentation: default
---

## Conceptos básicos de muestreo 

```{r, include=FALSE}
options(digits = 17)
```
* En todo estudio estadístico distinguiremos entre **población**, (conjunto de sujetos con una o varias características que podemos medir y deseamos estudiar), y **muestra**, (subconjunto de una población.)

* Dos tipos de análisis estadístico:
  * **Exploratorio** o  **descriptivo**: **estadística descriptiva**.
  * **Inferencial** o **confirmatorio**: **estadística  inferencial**.
  
## Conceptos básicos de muestreo 

Pasos en un estudio inferencial:

1. Establecer la característica que se desea estimar o la hipótesis que se desea contrastar.

2. Determinar la información (los datos) que se necesita para hacerlo.

3. Diseñar un experimento que permita recoger estos datos; este paso incluye:

    * Decidir qué tipo de muestra se va a tomar y su tamaño.
   
    * Elegir las técnicas adecuadas para realizar las inferencias deseadas a partir de la muestra que se tomará.

## Conceptos básicos de muestreo 

4. Tomar una muestra y medir los datos deseados sobre los individuos que la forman.

5. Aplicar las técnicas de inferencia elegidas con el *software* adecuado.

6. Obtener conclusiones.

7.  Si las conclusiones son fiables y suficientes, redactar un informe; en caso contrario, volver a empezar.

## Tipos de muestreo: Muestreo aleatorio con y sin reposición {-}

* Un **muestreo aleatorio** consiste en seleccionar una muestra de la población de manera que todas las muestras del mismo tamaño sean **equiprobables**.

* Dos tipos básicos de muestreo:
  * con reposición:
```{r, echo=FALSE, label=simple,fig.cap="Una muestra aleatoria simple"}
knitr::include_graphics("../teoria/modulo_estadistica/simplev.png",dpi=400)
```
En `R`
```{r}
sample(1:100, 15, replace=TRUE)
```

## Tipos de muestreo: Muestreo aleatorio con y sin reposición {-}
  * sin reposición:
```{r, echo=FALSE, label=sinrep,fig.cap="Una muestra aleatoria sin reposición"}
knitr::include_graphics("../teoria/modulo_estadistica/sinrepv.png",dpi=400)
```
En `R`
```{r}
sample(1:100, 15, replace=FALSE)
```

## Muestreo sistemático

* Suponemos que disponemos de una lista ordenada de todos los individuos de la población. Muestreo sistemático: tomarlos a intervalos constantes escogiendo al azar el primer individuo que elegimos:

```{r, echo=FALSE, label=sist,fig.cap="Una muestra aleatoria sistemática"}
knitr::include_graphics("../teoria/modulo_estadistica/sistv.png",dpi=400)
```

## Muestreo aleatorio estratificado {-}

* Este tipo de muestreo se utiliza cuando la población está clasificada en  **estratos** que son de interés para la propiedad estudiada.

* Se toma una muestra aleatoria de cada estrato y se unen en una muestra global. A este proceso se le llama **muestreo aleatorio estratificado**:
```{r, echo=FALSE, label=estratprevi,fig.cap="Una muestra aleatoria estratificada con dos estratos"}
knitr::include_graphics("../teoria/modulo_estadistica/estrat.png",dpi=400)
```

## Muestreo por conglomerados {-}
* El proceso de obtener y estudiar una muestra aleatoria en algunos casos es caro o difícil, incluso aunque dispongamos de la lista completa de la población.

* Una alternativa posible sería, en vez de extraer una muestra aleatoria de todos los individuos de la población, escoger primero al azar unos subconjuntos en los que la población está dividida, a las que llamamos en este contexto **conglomerados** (*clusters*):
```{r, echo=FALSE, label=clust,fig.cap="Una muestra aleatoria por conglomerados con 2 estratos y 20 conglomerados"}
knitr::include_graphics("../teoria/modulo_estadistica/cluster.png",dpi=400)
```

## Muestreo polietápico

* Una vez seleccionada la muestra aleatoria de conglomerados, tomar de alguna manera una muestra aleatoria de cada uno de ellos:
```{r, echo=FALSE, label=poli,fig.cap="Una muestra polietápica de 5 conglomerados y 3 bolas al azar sin reposición"}
knitr::include_graphics("../teoria/modulo_estadistica/poli.png",dpi=400)
```

## Guía rápida

* `sample(x, n, replace=...)` genera una muestra aleatoria de tamaño `n` del vector `x`, con reposición si igualamos `replace` a `TRUE` y sin reposición si lo igualamos a `FALSE` (su valor por defecto). Si `x` es un número natural $x$, representa el vector 1,2,...,$x$.

* `set.seed` permite fijar la semilla de aleatoriedad. 

* `replicate(n,expresión)` evalúa `n` veces la `expresión`, y organiza los resultados como las columnas de una matriz (o un vector, si el resultado de cada `expresión` es unidimensional).


## Estimación puntual

* Estudio inferencial: deducir información sobre la población a partir de los datos de la muestra. Dos formas:
  * Suponiendo que conocemos el **modelo** al que se ajusta la población: **estimación paramétrica**.
  * Suponiendo que desconocemos qué tipo de distribución tiene la variable aleatoria que modela la característica que nos interesa: **estimación no paramétrica**.
  
* Tres vías para obtener información sobre los parámetros de la distribución:
  * **Estimación puntual**.
  * **Estimación por intervalos de confianza**.
  * **Contraste de hipótesis**.

## Estimación puntual
Propiedades de un estimador:

* **Insesgado**: un estimador es **insesgado** cuando el valor esperado de la variable aleatoria que define coincide con el valor del parámetro poblacional que se quiere estimar.

* **Máximo verosímil**: un estimador es **máximo verosímil** cuando el resultado que da sobre cada muestra aleatoria es el valor del parámetro poblacional que maximiza la probabilidad de obtenerla.

## Estimación máximo verosímil

* Para la familia Bernoulli, el estimador máximo verosímil del parámetro $p$ es la proporción muestral de éxitos $\widehat{p}$. Este estimador es además insesgado.

* Para la familia Poisson, el estimador máximo verosímil  del parámetro $\lambda$ es la media muestral $\overline{X}$. Este estimador es de nuevo  insesgado.

* Para la familia geométrica, el estimador máximo verosímil del parámetro $p$ es ${1}/{\overline{X}}$. Este estimador es sesgado.

*   Para la familia exponencial, el estimador máximo verosímil del parámetro $\lambda$ es ${1}/{\overline{X}}$. Este estimador también es sesgado.

*  Para la familia normal, los  estimadores máximo verosímiles de la media $\mu$, la desviación típica $\sigma$ y la varianza $\sigma^2$ son, respectivamente, la media muestral $\overline{X}$, la desviación típica "verdadera" $S_X$ y la varianza "verdadera" $S_X^2$.


## Estimación con `R`

* Función `fitdistr` del paquete **MASS**:
```{r, eval=FALSE}
fitdistr(x, densfun=..., start=...)
```
donde

  *  `x` es la muestra, un vector numérico.

  *  El valor de `densfun` ha de ser el nombre de la familia de distribuciones:`"chi-squared"`, `"exponential"`, `"f"`, `"geometric"`,  `"lognormal"`,  `"normal"` y `"poisson"`. 

  *  Si `fitdistr` no dispone de una fórmula cerrada para el estimador  máximo verosímil de algún parámetro, usa un algoritmo numérico para aproximarlo que requiere de un valor inicial para arrancar. Este valor (o valores) se puede especificar igualando el parámetro `start` a una `list` con cada parámetro a estimar igualado a un valor inicial.  
  
## Guía rápida

*  `fitdistr` del paquete **MASS**, sirve para calcular los estimadores  máximo verosímiles  de los parámetros de una distribución a partir de una muestra. Parámetros principales:
    * `densfun`: el nombre de  la familia de distribuciones, entre comillas.
    * `start`: permite fijar el valor inicial del algoritmo numérico para calcular el estimador, si la función lo requiere.
