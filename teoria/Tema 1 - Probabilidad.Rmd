---
title: "Tema 1 - Probabilidad"
author: "Juan Gabriel Gomila, Arnau Mir y Ricardo Alberich"
date: '2019 DMI '
output:
  ioslides_presentation:
    css: Mery_style_2.css
    logo: Images/matriz_mov.gif
    widescreen: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Probabilidades Básicas




## Definiciones básicas
Principales definiciones

```{block type="definition"}
Experimento aleatorio
```


<l class="definition"> Experimento aleatorio </l>  experimento que  repetido  en las mismas condiciones puede  dar resultados diferentes, pero que a largo plazo son predecibles 


<l class="example"> Ejemplo tirar  un dado </l>  anotar el número de  puntos de la cara superior

<l class="definition" >Suceso elemental</l>: cada uno de los posibles resultados del experimento aleatorio


<l class="example"> Ejemplo dado </l>: epsdice{1}, epsdice{2}, epsdice{3}, epsdice{4}, epsdice{5}, epsdice{6}


<l class="definition"> Espacio muestral</l>  el conjunto  $\Omega$ formado por todos los sucesos elementales del experimento aleatorio


<div class="example"> Ejemplo 
$\Omega=$

```{r}
knitr::include_graphics("Images/basev.png",dpi=400)
```

</l>



## Definiciones básicas


<l class="definition"> Suceso <l> : Cualquier subconjunto del espacio muestral.

<l class="definition"> Alguno sucesos notables </l>

Suceso *seguro o cierto*
<!-- epsdice{1},epsdice{2},\epsdice{3},\epsdice{4},\epsdice{5},\epsdice{6} -->

Suceso *imposible o vació* $\Omegaptyset$

**Partes de un conjunto** $\PP(\Omega)$: conjunto de todos los sucesos del experimento aleatorio (conjunto de todos los subconjuntos de $\Omega$)


## Ejemplo $n$-grama

**Experimento aleatorio:** escoger al  azar un 3-grama  (tres letras consecutivas contando los blancos de inicio y final de palabra) de la palabra "\_Baleares\_" 


**Espacio muestral:* $\Omega=\{\_Ba, Bal, ale, lea, are, res, es\_\}$

**Algunos sucesos:**
$$
\begin{array}{l}
\{ale,are\} \quad \mbox{(3-gramas que empiezan por  $a$)} \\[2ex]
\{\_Ba,es\_\}\quad \mbox{(3-gramas de inicio y final de palabra)}\\[2ex]
\{Bal,ale,lea\} \quad \mbox{(3-gramas que contengan una ele)}
\end{array}
$$


## Operaciones

<div class="definition"> Operaciones con sucesos

$A,B\subseteq \Omega$:

* $\Omega$: *suceso* total o *seguro*
* $\Omegaptyset$:suceso  *vacío* o *imposible*
* $A\cup B$: suceso *unión*; el que ocurre si sucede $A$ o $B$
* $A\cap B$: suceso *intersección*; el que ocurre si sucede $A$ y $B$
* $A^c$: suceso *complementario*  el que sucede si NO sucede $A$.
* $A- B=A\cap B^c$: suceso *diferencia* (el que acontece  si sucede $A$ y NO sucede $B$.


$A$ y $B$ son *incompatibles* (o *disjuntos*) cuando  $A\cap B=\Omegaptyset$

</div>

## Ejemplo sexo



Supongamos que el sexo se divide entre Mujeres y Hombres.

$\blue{\Omega=}\{\mbox{Estudiantes de esta clase}\}$\\
$\blue{A=}\{\mbox{Mujeres de esta clase}\}$\\
$\blue{B=}\{\mbox{Estudiantes que son zurdos}\}$\\

* $\blue{A\cup B=}\{\mbox{Est. que son mujeres o que son zurdos}\}$
* $\blue{A\cap B=}\{\mbox{Mujeres de esta clase que son zurdas}\}$
* $\blue{A^c=}\{\mbox{Hombres de esta clase}\}$
* $\blue{A-B=}\{\mbox{Mujeres de la clases que \Omegaph{no} son zurdas}\}$
* $\blue{B-A=}\{\mbox{Hombres de la clase que son zurdos}\}$
* No son incompatibles PONER EMOJI :-)


## Propiedades
1. \Omegaph{Conmutativas:} $A\cup B=B\cup A$, $A\cap B=B\cap A$
2. \Omegaph{Asociativas:} $A\cup(B\cup C)=(A\cup B)\cup C$, $A\cap(B\cap C)=(A\cap B)\cap C$}
3. \Omegaph{Distributivas:} $A\cap(B\cup C)=(A\cap B)\cup (A\cap C)$, $A\cup(B\cap C)=(A\cup B)\cap (A\cup C)$


## Propiedades: gráficos

\begin{center}
\begin{tabular}{ccc}
\hspace*{-1.5cm}  $A$ & $B\cap C$ & $A\cup (B\cap C)$\\
\hspace*{-1.5cm} \includegraphics[width=0.25\linewidth]{distr11.jpg} &
\includegraphics[width=0.25\linewidth]{distr12.jpg} &
\includegraphics[width=0.25\linewidth]{distr13.jpg}\\[2ex]
\hspace*{-1.5cm} $A\cup B$ & $A\cup C$ & $(A\cup B)\cap (A\cup C)$\\
\hspace*{-1.5cm}\includegraphics[width=0.3\linewidth]{distr21.jpg} &
\includegraphics[width=0.25\linewidth]{distr22.jpg} &
\includegraphics[width=0.25\linewidth]{distr23.jpg}\\ 
\end{tabular}
\end{center}
\end{frame}


## Propiedades continuación
4. Complementario del complementario: $(A^c)^c=A$


\begin{center}
\begin{tabular}{ccc}
\hspace*{-1cm}  $A$ & $A^c$ & $(A^c)^c$\\
\hspace*{-1cm} \includegraphics[width=0.3\linewidth]{dd2.jpg} &
\includegraphics[width=0.3\linewidth]{dd1.jpg} &
\includegraphics[width=0.3\linewidth]{dd3.jpg}
\end{tabular}
\end{center}

## Propiedades continuación

5. **Leyes de De Morgan:** $(A\cup B)^c=A^c\cap B^c$, $(A\cap B)^c=A^c\cup B^c$

\begin{center}
\begin{tabular}{cc}
\hspace*{-1cm}  $A\cup B$ & $(A\cup B)^c$ \\
\hspace*{-1cm} \includegraphics[width=0.3\linewidth]{demorgan6.jpg} &
\includegraphics[width=0.3\linewidth]{demorgan7.jpg} \end{tabular}\\[2ex]
\begin{tabular}{ccc}
\hspace*{-1cm}  $A^c$ & $B^c$ & $A^c\cap B^c$\\
\hspace*{-1cm} \includegraphics[width=0.3\linewidth]{demorgan8.jpg} &
\includegraphics[width=0.3\linewidth]{demorgan9.jpg} & 
\includegraphics[width=0.3\linewidth]{demorgan10.jpg}
\end{tabular}\\[2ex]

\end{center}
%5\only<5>{
\item[(e)] \Omegaph{Leyes de De Morgan:} $(A\cup B)^c=A^c\cap B^c$, $(A\cap B)^c=A^c\cup B^c$


\begin{center}
\begin{tabular}{cc}
\hspace*{-1cm}  $A\cap B$ & $(A\cap B)^c$ \\
\hspace*{-1cm} \includegraphics[width=0.3\linewidth]{demorgan1.jpg} &
\includegraphics[width=0.3\linewidth]{demorgan2.jpg} \end{tabular}\\[2ex]
\begin{tabular}{ccc}
\hspace*{-1cm}  $A^c$ & $B^c$ & $A^c\cup B^c$\\
\hspace*{-1cm} \includegraphics[width=0.3\linewidth]{demorgan3.jpg} &
\includegraphics[width=0.3\linewidth]{demorgan5.jpg} & 
\includegraphics[width=0.3\linewidth]{demorgan4.jpg}
\end{tabular}\\[2ex]
## Definición de probabilidad

La probabilidad de un suceso es una puntuación (*score*) numérico entre 0 y 1 que mide la verosimilitud de que este evento se produzca.


Esta verosimilitud puede estar justificada por 

* Estimación personal

* Estimación de expertos

* La frecuencia con la que se da 

* Cálculo formal

## Definición de probabilidad

Sea $\Omega$ el espacio muestral de un experimento aleatorio. 
Supongamos que el número de posibles resultados, por el momento, es finito.

Una probabilidad sobre $\Omega$ es una aplicación

$$
P:{\cal P}(\Omega)\to [0,1]
$$
con las siguientes propiedades:

1. $0\leq P(A)\leq 1$, para todo suceso $A$ 
2. $P(\Omega)=1$
3. Si $\{A_1,A_2,\ldots,A_n\}$ son sucesos disjuntos dos a dos, entonces

$$
P(A_1\cup A_2\cup \cdots \cup A_n)=P(A_1)+P(A_2)+\cdots +P(A_n)
$$

Si $a\in \Omega$ es un suceso elemental cometeremos el abuso de notación de poner $P(a)$ en lugar de $P(\{a\})$

## Ejemplo: grupos sangíneos

En la página de la \href{http://www.donasang.org/que-es-la-sang/es_frequencies-dels-diferents-grups.html}{\blue{Fundación Banco de Sangre y Tejidos de las Islas Baleares}} podemos encontrar información sobre los porcentajes de tipos de sangre de los donantes de las Islas Baleares: 

A: 46%; B: 7.5%; AB: 3.5%; O: 43%

¿Cuál es la probabilidad de que un balear donante de sangre  no  sea del  tipo 0?


**Experimento aleatorio:** tipo de sangre de un paciente humano

$\Omega=\{\mbox{A,B,AB,O}\}$


**Probabilidad** de un suceso: se asimila al porcentaje observado de individuos

**Suceso:** $\{\mbox{O}\}^c=\{\mbox{A,B,AB}\}$

$\red{P(\{\mbox{O}\}^c)}\!=\!P(\{\mbox{A,B,AB}\})\!=\!
P(\mbox{A})+P (\mbox{B})+P(\mbox{AB})\!=\!0.55$


## Propiedades

1. $P(\Omegaptyset)=0$

2. $P(A-B)=P(A)-P(A\cap B)$\\
porque $P(A)=P(A-B)+P(A\cap B)$

```{r}
knitr::include_graphics("A-B.jpg")
```

3. Si $B\subseteq A$, entonces $0\leq P(B)\leq P(A)$

4.  $P(A^c)=1-P(A)$

## Propiedades
5.  $P(A\cup B)=P(A)+P(B)-P(A\cap B)$ porque

$$\begin{eqnarray*}
& P(A)+P(B)-P(A\cap B)= P(A-B)+P(A\cap B)\\
& + P(B-A)+ P(A\cap  B)-P(A\cap  B)\\
& =P(A-B)+P(A\cap B)+ P(B-A)=P(A\cup B)
\end{eqnarray*}
$$

```{r}
knitr::include_graphics("A-B.jpg")
```


## Propiedades continuación
6. $P(A\cup B\cup C)=P(A)+P(B)+P(C)$\\ \qquad $-P(A\cap B)-P(A\cap C)-P(B\cap C)$\\ \qquad $+P(A\cap B\cap C)$


```{r}
knitr::include_graphics("tresconjunts.jpg")
```

$P(A\cup B\cup C)=P(1)+P(2)+P(3)+P(4)+P(5)+P(6)+P(7)$

## Propiedades continuación
\begin{enumerate}[(a)]
7. Si $A=\{a_1,a_2,\ldots,a_k\}$, entonces
$$
P(A)=P(a_1)+P(a_2)+\cdots+P(a_k)
$$

8. Si todos los sucesos elementales tienen la misma probabilidad,
$$
P(A)=\frac{|A|}{|\Omega|}\Big(=\frac{\mbox{casos favorables}}{\mbox{casos posibles}}\Big)
$$
## Ejemplo: Fecencia de letras 

Los porcentajes de vocales de un determinado idioma (de alfabeto latino) son:

https://es.wikipedia.org/wiki/Frecuencia_de_aparici%C3%B3n_de_letras

A: 18.7\%; E: 26.1\%; I: 25.7\%; O: 24.4\% U: 5.1\%

¿Cuál es la probabilidad que  una vocal escogida al azar de este idioma sea una E o una O?


$\Omega=\{A,E,I,O,U\}$

Suceso$=\{E,0\}$

$P(\{E,I\})=P(E)+P(O)=0.261+0.244=0.505$

## Ejemplo

https://elpais.com/politica/2019/01/02/actualidad/1546426491_623324.html

%cocaína, metanfetamina, opiáceos, cannabis y anfetaminas

En un control especial de la policía el $0.1\%$ de todos los conductores analizados en un control de tráfico dan  positivo en un el test  en cocaína, y  el $1\%$ da positivo  en cannabis. Un $1.05\%$ da positivo en alguno de los dos test. 

¿Cuál  es la probabilidad que un individuo analizado  en el control de drogas  escogido  al azar no de positivo  en ninguno de lo dos test?

$A$: dar positivo  en cocaína; $P(A)=0.001$

$B$: dar positivo en cannabis; $P(B)=0.01$

$A\cup B$: dar positivo en alguno de los dos test; $P(A\cup B)=0.0105$

$(A\cup B)^c$: no dar positivo en ninguno de los test

$P((A\cup B)^c)=1-P(A\cup B)=1-0.0105=0.9895$



## Ejemplos: control de  tráfico

En un control especial de la policía el $0.1\%$ de todos los conductores analizados en un control de tráfico dan  positivo en un el test  en cocaína, y  el $1\%$ da positivo  en cannabis. Un $1.05\%$ da positivo en alguno de los dos test. 

¿Cuál  es la probabilidad que un analizado  al azar de positivo en los dos test en cocaína y cannabis?

$A$: dar positivo en cocaína; $P(A)=0.001$

$B$: dar positivo en cannabis; $P(B)=0.01$

$A\cup B$: dar positivo en algún de los dos test; $P(A\cup B)=0.0105$

$A\cap B$: dar positivo en los dos test

$\begin{array}{rl}
{P(A\cap B)} &{=P(A)+P(B)-P(A\cup B)}\\ &{=0.001+0.01-0.0105=0.0005}
\end{array}$

## Ejemplos control tráfico 2


En un control especial de la policía el $0.1\%$ de todos los conductores analizados en un control de tráfico dan  positivo en un el test  en cocaína, y  el $1\%$ da positivo  en cannabis. Un $1.05\%$ da positivo en alguno de los dos test. 

¿Cuál es la probabilidad de  que un conductor analizado de  positivo en cocaína pero no en cannabis?}

$A$: dar positivo en cocaína; $P(A)=0.001$

$B$: dar positivo en cannabis; $P(B)=0.01$

$A\cap B$: dar positivo en los dos test; $P(A\cap B)=0.0005$


$B-A$: dar positivo en  cocaína pero no en cannabis

$P(B-A) =P(B)-P(A\cap B) =0.01-0.0005=0.0095$


# Probabilidad condicionada
blaha blah 

## Probabilidad condicionada

Dados dos sucesos  $A$  y $B$, con $P(A)>0$, la  \Omegaph{probabilidad $P(B|A)$ de $B$ condicionado a $A$} es la probabilidad

* de que suceda  $B$ suponiendo que pasa $A$ 
* de que si pasa $A$, entonces suceda $B$
* de que un resultado de $A$ también pertenezca a $B$

Se calcula así:

$$
P(B|A)=\frac{P(A\cap B)}{P(A)}
$$


## Ejemplo,frecuencia sexo y gafas

En una clase de 20 hombres  y 30 mujeres, 15 hombres y 18 mujeres llevan gafas.

1. ¿Cuál es la probabilidad de que un alumno lleve gafas?

$$
\frac{33}{50}
$$

2. ¿Cuál es la probabilidad de que un alumno sea mujer y lleve gafas?

$$
\frac{18}{50}
$$


### Ejemplo: sexo y gafas

En una clase de 20 hombres  y 30 mujeres, 15 hombres y 18 mujeres llevan gafas.



3. ¿Cuál es la probabilidad de que un chica lleve gafas?

$$
\frac{18}{30}=\frac{18/50}{30/50}=\frac{P(\mbox{mujer  y gafas})}{P(\mbox{mujer})}
$$


4. Si escogemos un estudiante al azar ¿Cuál es la probabilidad que si es mujer, entonces lleve gafas?

$$
\frac{18}{30}
$$




## Ejemplo

En una clase de 20 hombres  y 30 mujeres, 15 hombres y 18 mujeres llevan gafas.

5.  ¿Cuál es la probabilidad de que un alumno que lleve gafas sea mujer?

$$
\frac{18}{33}=\frac{18/50}{33/50}=\frac{P(\mbox{mujer y gafas})}{P(\mbox{gafas})}
$$


6. Si escogemos un estudiante al azar  ¿Cuál es la probabilidad de que si lleva gafas, entonces sea mujer?
$$
\frac{18}{33}
$$


## Alerta

Hay que distinguir bien entre

* $P(A\cap B)$: probabilidad de $A$ $\color{red}{\text{y}}$ $B$

**Probabilidad de que sea mujer y  lleve gafas**

* $P(A|B)$: probabilidad de que $\color{red}{\text{si}}$ pasa $B$, $\color{red}{\text{entonces}}$ pase $A$

\begin{quote}
Probabilidad de que, si es mujer, lleve gafas
\end{quote}

\end{itemize}


Cuando utilizamos probabilidad condicional  $P(A|B)$ estamos restringiendo el espacio muestral a $B$

## Probabilidad condicionada. Propiedades}

La probabilidad condicionada es una probabilidad

$\color{blue}{\text{Propiedad}}$

Sea $A\subseteq \Omega$ un suceso tal que $P(A)>0$. entonces

$$
\begin{array}{rccl}
P(-|A):& \mathcal{P}(\Omega) & \to & [0,1]\\
&B & \mapsto & P(B|A)
\end{array}
$$
satisface las propiedades de las probabilidades

Por ejemplo:

$$
\begin{array}{l}
P(B^c|A)=1-P(B|A)\\
P(B_1\cup B_2|A)=P(B_1|A)+P(B_2|A)-P(B_1\cap B_2|A)
\end{array}
$$


## Ejemplos

Un 15\% de los adultos son hipertensos, un 25\% de los adultos creen que son hipertensos, y un 9\% de los adultos son hipertensos y creen que lo son.

$\color{red}{\text{Si un adulto cree que es hipertenso, cuál es la probabilidad que lo sea?}}$

$A$: ser hipertenso; $P(A)=0.15$ 

$B$: creer ser hipertenso; $P(B)=0.25$

$A\cap B$: ser hipertenso y creerlo; $P(A\cap B)=0.09$

$P(A|B)=\dfrac{P(A\cap B)}{P(B)}=\dfrac{0.09}{0.25}=0.36$

## Ejemplo

Un 15\% de los adultos son hipertensos, un 25\% de los adultos creen que son hipertensos, y un 9\% de los adultos son hipertensos y creen que lo son.

$\color{red}{\text{Si un adulto es hipertenso, ¿cuál es la probabilidad que crea que lo es?}}$

$A$: ser hipertenso; 
$B$: creer ser hipertenso

$P(B|A)$?
$$
\begin{array}{rl}
P(B|A) & =\dfrac{P(A\cap B)}{P(A)}=\dfrac{0.09}{0.15}=
0.6
\end{array}
$$

## Ejemplos

Un dígito de control de error toma  el valor 0  en el 99\% de los casos en que hay un error. Si la probabilidad de error en un mensaje es  del $0.5\%$. \blue{¿cuál  es la probabilidad de que el mensaje sea erróneo y el código de error tenga valor 0?


$B$: mensaje con error; $P(B)=0.005$

$A$: código de error vale 0;
$P(A|B)=0.99$

$P(A\cap B)=P(B)\cdot P(A|B)=0.005\cdot 0.99=0.00495$


## Ejemplos

Un 50\% de  correos recibidos en un servidor llevan adjuntos  y un 65\% son  publicidad no deseada (SPAM). Sólo un 15\% de estos correos no llevan adjuntos y no son SPAM. 

* ¿Cuál  es la probabilidad que un correo  lleve adjunto si es SPAM?

* ¿Cuál es la probabilidad que un correo **no** tenga adjuntos si **no**  es SPAM?


## Ejemplos

Un 50\% de  correos recibidos en un servidor llevan adjuntos  y un 65\% son  publicidad no deseada (SPAM). Sólo un 15\% de estos correos no llevan adjuntos y no son SPAM. 


* $\color{blue}{\text{¿Cuál es la probabilidad de que un correo tenga adjuntos si es SPAM?}}$

$A$: llevar adjuntos; $P(A)=0.5$

$S$: SPAM; $P(S)=0.65$

$A^c\cap S^c=(A\cup S)^c$: no llevar adjunto y no ser SPAM; $P((A\cup S)^c)=0.15$

$P(A|S)=\dfrac{P(A\cap S)}{P(S)}=?$

## Ejemplos

Un 50\% de  correos recibidos en un servidor que  llevan adjuntos  y un 65\% son  publicidad no deseada (SPAM). Sólo un 15\% de estos correos no llevan adjuntos y no son SPAM. 

* $\color{blue}{\text{¿Cuál es la probabilidad que un correo lleve adjuntos si es SPAM?}}$


$P(A)=0.5, P(S)=0.65$,\\ $P(A^c\cap S^c)=P((A\cup S)^c)=0.15$

$P(A\cup S)=1-P((A\cup S)^c)=0.85$

$P(A\cap S)=P(A)+P(S)-P(A\cup S)=0.3$

$P(A|S)=\dfrac{P(A\cap S)}{P(S)}=\dfrac{0.3}{0.65}\approx 0.46$


## Ejemplos SPAM continuación

Un 50\% de  correos recibidos en un servidor que  llevan adjuntos  y un 65\% son  publicidad no deseada (SPAM). Sólo un 15\% de estos correos no llevan adjuntos y no son SPAM. 

* $\color{blue}{\text{¿Cuál  es la probabilidad de que un correo no lleve adjuntos si  no es SPAM?}}%

$P(A)=0.5, P(S)=0.65$,\\ $P(A^c\cap S^c)=P((A\cup S)^c)=0.15$

$P(A^c|S^c)=\dfrac{P(A^c\cap S^c)}{P(S^c)}=\dfrac{P(A^c\cap S^c)}{1-P(S)}=\dfrac{0.15}{0.35}\approx 0.43$


## Teorema de la probabilidad total

**teorema**

Dados dos sucesos $A$ y $B$ se tiene que 

$$
\begin{array}{rl}
P(B)&= P(B\cap A) +P(B\cap A^c)\\
& =P(A)\cdot P(B|A)+ P(A^c)\cdot P(B|A^c)
\end{array}
$$


## Teorema de la probabilidad total

Los sucesos $A_1,A_2,\ldots, A_n$ son  una **partición** del espacio muestral $\Omega$ de un determinado experimento aleatorio, si cumplen las condiciones siguientes:

1. $A_1\cup A_2\cup\ldots\cup A_n=\Omega$
2. $A_1,A_2,\ldots,A_n$ son incompatibles dos a dos ($A_i\cap A_j=\Omegaptyset$)

**teorema**
Sea $A_1,A_2,\ldots,A_n$ una partición de $\Omega$. Sea $B$ un suceso cualquiera. Entonces

$$
\begin{array}{rl}
P(B)&= P(B\cap A_1)+\cdots +P(B\cap A_n)\\
& =P(A_1)\cdot P(B|A_1)+\ldots+P(A_n)\cdot P(B|A_n)
\end{array}
$$



## Ejemplos

Un dígito de control de error toma  el valor 0  en un $99\%$ de los casos en que hay un error y en un $5\%$  de los mensajes sin error.
La probabilidad de error en un mensaje es  del $0.5\%$ 

¿Cuál es la probabilidad de  que un mensaje escogido al azar tenga el dígito de control a 0?



$B$: mensaje con error; $P(B)=0.005$


$A$: código de error vale 0;
$P(A|B)=0.99$





$P(A|B)=0.99, P(A|B^c)= 0.05$

$$
\begin{array}{rl}
P(A) & =P(B)\cdot P(A|B)+P(B^c)\cdot P(A|B^c)\\ &
=0.005\cdot 0.99+0.995\cdot 0.05=0.0547\end{array}
$$



## Clasificación o Diagnósticos

Consideremos alguna de las siguientes situaciones:

* Un algoritmo detecta si una transacción con tarjeta de crédito es fraude o no.
* Un algoritmo detecta si  tiene o no que mostrar un anuncio en una web.
\item Un prueba de embarazo. 
\item Una prueba médica  para  una enfermedad concreta.
\end{itemize}
\end{frame}

\begin{frame}
\frametitle{Clasificación o Diagnósticos}
Nos ceñiremos a la casuística más elemental  el algoritmo de clasificación o la diagnosis solo da dos resultado Positivo (sí tienes la enfermedad, sí es un fraude) o Negativo (en caso contrario). 

\vfill
En todas estas situaciones  podemos calcular lo que se llama \Omegaph{matriz de confusión} que representa todas las situaciones posibles:
\vfill
\begin{centering}
\begin{tabular}{c||c|c}
 & Test Positivo & Test Negativo \\\hline
Es del tipo & Correcto & Error\\
No Es del tipo & Error & Correcto\\\hline
\end{tabular}
\end{centering}
\end{frame}

\begin{frame}
En general los  modelos y algoritmos de clasificación suelen aportar puntuaciones (\Omegaph{scores}) que determinan el grado de pertenencia a  una clase, o que miden si dos objetos están en la misma clase.

Así  el resultado del clasificador o del diagnóstico  puede ser:

\begin{itemize}
\item \red{un número real}, en cuyo caso debe clasificador entre cada clase debe determinarse por un valor umbral  (\Omegaph{threshold}) por ejemplo para determinar si una persona está estresado podemos dar un \Omegaph{scores} entre 0 y 1 (1 máximo estrés 0 estrés nulo):
\item o podemos dar \red{un resultado discreto} que indica directamente una de las clases (esto es necesario si es un algoritmo que debe decidir  qué hacer con el objeto.
\item  Buen momento para un vídeo: \href{https://www.youtube.com/watch?v=pqTntG1RXSY}{\blue{Is Hot Dog}}. 

\end{itemize}
\end{frame}

% \begin{frame}
% Consideremos un problema de predicción de clases binario, en la que los resultados se etiquetan positivos (P) o negativos (N). Hay cuatro posibles resultados a partir de un clasificador binario como el propuesto. Si el resultado de una exploración es P y el valor dado es también P, entonces se conoce como un Verdadero Positivo (VP); sin embargo si el valor real es N entonces se conoce como un Falso Positivo (FP). De igual modo, tenemos un Verdadero Negativo (VN) cuando tanto la exploración como el valor dado son N, y un Falso Negativo (FN) cuando el resultado de la predicción es N pero el valor real es P.
% \end{frame}



% \begin{frame}
% 
% Un ejemplo aproximado de un problema real es el siguiente: consideremos una prueba diagnóstica que persiga determinar si una persona tiene una cierta enfermedad. Un falso positivo en este caso ocurre cuando la prueba predice que el resultado es positivo, cuando la persona no tiene realmente la enfermedad. Un falso negativo, por el contrario, ocurre cuando el resultado de la prueba es negativo, sugiriendo que no tiene la enfermedad cuando realmente sí la tiene.
% \end{frame}

\begin{frame}
\frametitle{Clasificación o Diagnósticos}
%Definamos un experimento a partir de P instancias positivas y N negativas. Los cuatro posibles resultados se pueden formular en una Tabla de contingencia (o Matriz de confusión) 2x2 como sigue: 
En un diagnósticos de una  cierta  condición (por Ejemplo, test embarazo, test de enfermedad), tenemos dos tipos de sucesos:
\begin{itemize}
\item $T$: el test da positivo
\item $M$: el sujeto satisface la condición
\end{itemize}
entonces
\begin{itemize}
\item \Omegaph{Falsos positivos} $T\cap M^c$: El test da positivo, pero la condición no es da
\item \Omegaph{Coeficiente de falsos positivos:} $P(T|M^c)$
\item \Omegaph{Falsos negativos} $T^c\cap M$: El test da negativo, pero la condición sí que se da
\item \Omegaph{Coeficiente de falsos negativos:} $P(T^c|M)$
\end{itemize}
\end{frame}



\begin{frame}
\frametitle{Ejemplos}

Un test diseñado para diagnosticar una determinada enfermedad tiene un coeficiente de falsos negativos de 0.06, y un coeficiente de falsos positivos de 0.04. En un estudio masivo se observa que un 15\% de la población da positivo al test.

¿Cuál es la probabilidad que una persona escogida aleatoriamente  tenga esta enfermedad?


$T$: dar positivo al test; $P(T)=0.15$


$M$: tener la enfermedad

$P(T)=0.15$, $P(T^c|M)=0.06$, $P(T|M^c)=0.04$

 $P(M)$?

## Ejemplos

$P(T)=0.15$, $P(T^c|M)=0.06$, $P(T|M^c)=0.04$
$$
P(T) =P(M)\cdot P(T|M)+P(M^c)\cdot P(T|M^c)
$$
donde

$$
\begin{array}{l}
P(T|M)=1-P(T^c|M)=0.94 \\[1ex]
P(M^c)=1-P(M)
\end{array}
$$

Por lo tanto

$$
\begin{array}{rl}
0.15 & = P(M)\cdot 0.94+(1-P(M))\cdot 0.04\\
 & =0.04+0.9P(M)\\[1ex]
P(M) & =\dfrac{0.11}{0.9}\approx 0.1222.
\end{array}
$$



# Bayes

## Fórmula de Bayes
**teorema: Teorema de Bayes**
Sean $A$ y $B$ dos sucesos. Si $P(B)>0$, entonces

$$
\begin{array}{rl}
P(A|B) & \hspace*{-1ex} =\dfrac{P(A)\cdot P(B|A)}{P(B)}\\[2ex]
&\hspace*{-1ex} =\dfrac{P(A)\cdot P(B|A)}{P(A)\cdot P(B|A)+P(A^c)\cdot P(B|A^c)}
\end{array}
$$

Motivo: $P(A|B) =\dfrac{P(A\cap B)}{P(B)}=\cdots$




## Fórmula de Bayes
**teorema Teorema de Bayes**

Sea $A_1,A_2,\ldots,A_n$ una partición de $\Omega$. Sea $B$ un suceso tal que $P(B)>0$. entonces(para cualquier $i=1,2,\ldots,n$):

$$
\begin{array}{rl}
P(A_i|B) & \hspace*{-1ex} =\dfrac{P(A_i)\cdot P(B|A_i)}{P(B)}\\[2ex]
&\hspace*{-1ex} =\dfrac{P(A_i)\cdot P(B|A_i)}{P(A_1)\cdot P(B|A_1)+\cdots+P(A_n)\cdot P(B|A_n)}
\end{array}
$$

Motivo: $P(A_i|B) =\dfrac{P(A_i\cap B)}{P(B)}=\cdots$

## Ejemplos

Un test para detección de VIH da positivo un 99\% de los casos en los que  está presente y en un 5\% de los casos  en los que  el virus está ausente. En una población con un  $0.5\%$ de infectados por VIH, cuál es la probabilidad que un individuo que  haya dado positivo en el test esté infectado?



$A$: individuo infectado


$B$: el test da positivo


$$
\begin{array}{rl}
P(A|B) & =\dfrac{P(B|A)\cdot P(A)}{P(B|A)\cdot P(A)+P(B|A^c)\cdot P(A^c)}\\[2ex]
&=\dfrac{0.99\cdot 0.005}{0.005\cdot 0.99+0.995\cdot 0.05}=0.09\end{array}
$$

## Ejemplos

Un test para detección de VIH da positivo un 99\% de los casos en los que  está presente y en un 5\% de los casos  en los que el virus está ausente. En una población con un  $0.5\%$ de infectados por VIH, ¿cuál es la probabilidad de que un individuo que haya dado  \Omegaph{negativo} en el test \Omegaph{no} esté infectado?



$A$: individuo infectado


$B$: el test da positivo


$$\begin{array}{rl} P(A^c|B^c)& =\dfrac{P(B^c|A^c)\cdot P(A^c)}{P(B^c|A)\cdot P(A)+P(B^c|A^c)\cdot P(A^c)}\\[2ex] & =\dfrac{0.95\cdot 0.995}{0.01\cdot 0.005+0.95\cdot 0.995}=0.999947\end{array}
$$

## Ejemplos

Se ha observado que  los cientes de una empresa de ventas por internet son de tres tipos, 
A, B y C, disjuntos dos a dos. La probabilidad que  ser de cualquiera de cada uno de los tipos es $1/3$, pero la probabilidad de compra de cada tipo es diferente:  si es de tipo A  compra un 50\% de las veces,  si de tipo B, un 75\% de las veces, y de tipo C, un 60\%.

Supongamos que llega un cliente ¿cuál es la  probabilidad de  que si ha comprado sea del tipo B?

## Ejemplos

$A$: el cliente es de tipo  A; $B$:  el cliente es de tipo B; $C$:  el cliente es de tipo C;

 $P(A)=P(B)=P(C)=1/3$


$E$: el cliente compra

$P(E|A)=0.5, P(E|B)=0.75, P(E|C)=0.6$

$P(B|E)\!=\!\dfrac{P(E|B)\cdot P(B)}{P(E|A)\!\cdot\! P(A)\!+\!P(E|B)\!\cdot\! P(B)\!+\!P(E|C)\!\cdot\! P(C)}\!=\!\ldots$


## Ejemplos

Un test de detección precoz de abandono de clientes de una  empresa de telefonía  da  positivo el 97.5\% de las ocasiones en las que, posteriormente, el cliente se da de baja, y un 12\% de las veces en que no se dio de baja. La probabilidad que un cliente escogido al azar se dé de baja es de un 2\%.


* $\color{blue}{\text{¿Cuál  es la probabilidad que un individuo escogido al azar de positivo  en el test?}}$
* $\color{blue}{\text{¿Cuál  es la probabilidad que un individuo escogido al azar se de de  baja y dé positivo en el test?}}$
* $\color{blue}{\text{¿Cuál  es la probabilidad que un individuo  que dé negativo en el test se dé de baja?}}$

## Ejemplos

Un test de detección precoz de abandono de clientes de una entidad bancaria  da  positivo el 97.5\% de las ocasiones en las que posteriormente el cliente de da de baja, y un 12\% de las veces en que no se dio de baja. La probabilidad que un cliente escogido al azar se dé de baja es de un 2\%.


$T$: Dar positivo al test

$B$: darse de baja; $P(M)=0.02$


$P(T|B)=0.975, P(T|B^c)=0.12$


## Ejemplos

$P(B)=0.02$, $P(T|B)=0.975$, $P(T|B^c)=0.12$

$\color{blue}{\text{¿Cuál  es la probabilidad que un individuo escogido al azar de positivo  en el test?}}$

$$
\begin{array}{rl}
P(T) = & P(B)\cdot P(T|B)+P(B^c)\cdot P(T|B^c)\\[1ex]
& =0.02\cdot 0.975+0.98\cdot 0.12=0.1371
\end{array}
$$


## Ejemplos

$P(B)=0.02$, $P(T)=0.1371$, $P(T|B)=0.975$, $P(T|B^c)=0.12$


$\color{blue}{\text{¿Cuál  es la probabilidad que un individuo escogido al azar se de de  baja y dé positivo en el test?}}$

$P(B\cap T)= P(B)\cdot P(T|B)=0.02\cdot 0.975=0.0195$


## Ejemplos

$P(B)=0.02$, $P(T)=0.1371$, $P(T|B)=0.975$, $P(T|B^c)=0.12$


$\color{blue}{\text{¿Cuál  es la probabilidad que un individuo  que dé negativo en el test se dé de baja?}}$

$$
\begin{array}{rl}
P(B|T^c)= &\displaystyle \frac{P(B\cap T^c)}{P(T^c)}=
\frac{P(B)-P(B\cap T)}{1-P(T)}\\[2ex] & \displaystyle =
\frac{0.02-0.0195}{1-0.1371}\approx 0.00058
\end{array}
$$

## Ejemplos

$P(B)=0.02$, $P(T)=0.1371$, $P(T|B)=0.975$, $P(T|B^c)=0.12$



$\color{blue}{\text{¿Cuál  es la probabilidad que un individuo  que dé negativo en el test se dé de baja?}}$


O también se obtiene  así
$$
P(B|T^c)=\frac{P(T^c|B)\cdot P(B)}{P(T^c|B)\cdot P(B)+P(T^c|B^c)\cdot P(B^c)}
$$
donde
$$
\begin{array}{l}
P(T^c|B)=1-P(T|B)=0.025,\\[1ex] P(T^c|B^c)=1-P(T|B^c)=0.88
\end{array}
$$


# Independencia

# Sucesos independientes

Diremos que  los sucesos $A$ y  $B$ son **independientes** si  $P(A\cap B)=P(A)\cdot P(B)$


$A_1,\ldots, A_n$ son sucesos \Omegaph{independientes} cuando, para  toda
subfamilia $A_{i_1},\ldots,A_{i_k}$,
$$
P(A_{i_1}\cap \cdots\cap A_{i_k})=P(A_{i_1})\cdots P(A_{i_k})
$$

**propiedad**
Dados dos sucesos  $A$ y $B$ con  $P(A),P(B)>0$,  las siguientes afirmaciones son equivalentes:

1. $A$ y $B$ son independientes 

2. $P(A|B)=P(A)$

3. $P(B|A)=P(B)$

## Sucesos independientes
*
**propiedad**
Las siguientes afirmaciones son equivalentes:

1. $A$ y $B$ son independientes.
2. $A^c$ y $B$ son independientes.
3. $A$ y $B^c$ son independientes.
4. $A^c$ y $B^c$ son independientes.

## Ejemplo billete avión

En la web de viajes WEBTravel, el 55\% de los clientes compra billete de avión, el $20\%$  alojamiento en hotel, y el $60\%$  billete de avión  o alojamiento en hotel. ¿Son los sucesos comprar billete de avión y  comprar alojamiento en hotel independientes?


$A$: comprar billete de avión; $P(A)=0.55$


$B$: comprar alojamiento; $P(B)=0.2$


## Ejemplo billete avión

$$
\begin{array}{rl}
P(A\cap B) & \hspace*{-1ex}=P(A)+P(B)-P(A\cup B)\\ & \hspace*{-1ex}=0.55+0.2-0.6=0.15\\[1ex]
P(A)\cdot P(B) &  \hspace*{-1ex}= 0.55\cdot 0.2=0.11
\end{array}
$$
Son dependientes

